{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d3f381",
   "metadata": {},
   "source": [
    "[用之前将Notebook置于项目根目录下运行]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55791a20",
   "metadata": {},
   "source": [
    "# 1 准备数据集\n",
    "\n",
    "以BloodMNIST数据集为例。\n",
    "\n",
    "准备好数据集，将数据集数据装入Dataloader中用于批量特征提取。\n",
    "\n",
    "并准备好以下变量：\n",
    "1. `label_list`: 标签文本列表，如BloodMNIST的标签文本列表为`['basophil', 'eosinophil', ...]`\n",
    "2. `label_prompt_template_list`：用于标签的提示词模板列表。样例：\n",
    "    ```python\n",
    "    label_prompt_template_list = [\n",
    "    \"a microscopic image of a {} cell\",\n",
    "    \"a peripheral blood smear image of a {}\",\n",
    "    \"a bloodcell of {}\"\n",
    "    ]\n",
    "    ```\n",
    "3. `concept_list`: 概念文本列表，如BloodMNIST的概念文本列表可为`['Segmented nucleus','Band nucleus (band form)','Reniform / indented nucleus','Round nucleus', ...]`\n",
    "4. `concept_prompt_template_list`：用于概念的提示词模板列表。样例：\n",
    "    ```python\n",
    "    concept_prompt_template_list = [\n",
    "    \"a cell photo with sign of {}\",\n",
    "    \"a photo of a cell with {}\",\n",
    "    \"a cell image indicating {}\",\n",
    "    ]\n",
    "    ```\n",
    "5. `train_loader`, `test_loader`, `valid_loader`: 分别为训练集、测试集、验证集的Dataloader (torch.utils.data.DataLoader)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71a753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import medmnist\n",
    "from medmnist import BloodMNIST, INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee96c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择BloodMNIST数据集的信息\n",
    "data_flag = 'bloodmnist'\n",
    "info = INFO[data_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50c2c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basophil',\n",
       " 'eosinophil',\n",
       " 'erythroblast',\n",
       " 'immature granulocytes',\n",
       " 'lymphocyte',\n",
       " 'monocyte',\n",
       " 'neutrophil',\n",
       " 'platelet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签映射字典 label_map\n",
    "label_map = {int(k): v for k, v in info['label'].items()}  # 如 0:'basophil', 1:'eosinophil', ...\n",
    "label_map[3] = 'immature granulocytes'\n",
    "\n",
    "# 创建标签文本列表\n",
    "label_list = [label_map[idx] for idx in sorted(label_map.keys())]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c094b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择15个细胞特征作为概念（手动选择）\n",
    "cell_features = [\n",
    "    {\"en\": \"Segmented nucleus\", \"zh\": \"分叶细胞核\"},\n",
    "    {\"en\": \"Band nucleus (band form)\", \"zh\": \"带状细胞核（未分叶）\"},\n",
    "    {\"en\": \"Reniform / indented nucleus\", \"zh\": \"肾形/凹陷细胞核\"},\n",
    "    {\"en\": \"Round nucleus\", \"zh\": \"圆形细胞核\"},\n",
    "    {\"en\": \"Fine azurophilic granules\", \"zh\": \"细嗜天青颗粒\"},\n",
    "    {\"en\": \"Eosinophilic granules\", \"zh\": \"嗜酸性颗粒（橙红）\"},\n",
    "    {\"en\": \"Basophilic granules\", \"zh\": \"嗜碱性颗粒（深紫粗颗粒）\"},\n",
    "    {\"en\": \"Basophilic cytoplasm\", \"zh\": \"嗜碱性胞质\"},\n",
    "    {\"en\": \"Cytoplasmic vacuoles\", \"zh\": \"胞质空泡\"},\n",
    "    {\"en\": \"High nuclear-to-cytoplasmic ratio\", \"zh\": \"高核浆比\"},\n",
    "    {\"en\": \"Pale cytoplasm\", \"zh\": \"淡染胞质\"},\n",
    "    {\"en\": \"Nucleated erythrocyte (erythroblast)\", \"zh\": \"有核红细胞（幼红细胞）\"},\n",
    "    {\"en\": \"Platelet fragments / clumps\", \"zh\": \"血小板碎片/成团\"},\n",
    "    {\"en\": \"Stain precipitate (artifact)\", \"zh\": \"染色沉淀（伪影）\"},\n",
    "    {\"en\": \"Overlapping cell clumps (artifact)\", \"zh\": \"细胞重叠/成团（伪影）\"}\n",
    "]\n",
    "\n",
    "# 生成概念文本列表\n",
    "concept_list = [cell_feature[\"en\"] for cell_feature in cell_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备Prompt模板\n",
    "concept_prompt_template_list = [\"a cell photo with sign of {}\",\n",
    "                   \"a photo of a cell with {}\",\n",
    "                   \"a cell image indicating {}\",\n",
    "                   \"an image of a cell showing {}\",\n",
    "                   \"blood cell with {}\",\n",
    "                   \"a blood cell photo with sign of {}\",\n",
    "                   \"a photo of a blood cell with {}\",\n",
    "                   \"a blood cell image indicating {}\",\n",
    "                   \"an image of blood cell showing {}\"\n",
    "                   ]\n",
    "\n",
    "label_prompt_template_list = [\"a microscopic image of a {} cell\",\n",
    "                         \"a peripheral blood smear image of a {}\",\n",
    "                         \"a bloodcell of {}\"\n",
    "                         ]\n",
    "\n",
    "DB_METADATA = {\n",
    "    \"label_texts\": label_list,\n",
    "    \"prompt_temp_for_labels\": label_prompt_template_list,\n",
    "    \"concept_texts\": concept_list,\n",
    "    \"prompt_temp_for_concepts\": concept_prompt_template_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3f2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\chenk\\.medmnist\\bloodmnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\chenk\\.medmnist\\bloodmnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\chenk\\.medmnist\\bloodmnist_224.npz\n",
      "num_train: 11959 sample shape: (3, 224, 224)\n",
      "num_test: 3421 sample shape: (3, 224, 224)\n",
      "num_valid: 1712 sample shape: (3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "DataClass = getattr(medmnist, info['python_class'])  # 通过DataClass类获取BloodMNIST子类\n",
    "\n",
    "common_tf = transforms.Compose([\n",
    "    # Converts a PIL Image or numpy.ndarray (H x W x C) in the range[0, 255] \n",
    "    # to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    transforms.ToTensor(),])\n",
    "\n",
    "ds_train = DataClass(split='train', size=224, as_rgb=True, mmap_mode='r', transform=common_tf, download=True)\n",
    "ds_test = DataClass(split='test', size=224, as_rgb=True, mmap_mode='r', transform=common_tf, download=True)\n",
    "ds_valid = DataClass(split='val', size=224, as_rgb=True, mmap_mode='r', transform=common_tf, download=True)\n",
    "\n",
    "print(\"num_train:\", len(ds_train), \"sample shape:\", np.array(ds_train[0][0]).shape)  # (224, 224, 3)\n",
    "print(\"num_test:\", len(ds_test), \"sample shape:\", np.array(ds_test[0][0]).shape)  # (224, 224, 3)\n",
    "print(\"num_valid:\", len(ds_valid), \"sample shape:\", np.array(ds_valid[0][0]).shape)  # (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5de7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Dataloader\n",
    "train_loader = DataLoader(ds_train, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(ds_test, batch_size=64, shuffle=False)\n",
    "valid_loader = DataLoader(ds_valid, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b649e",
   "metadata": {},
   "source": [
    "# 2 载入CLIP模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52db85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\chenk\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "{'type': 'user', 'id': '6693342048f8a55b7eba3d8e', 'name': 'takedachia', 'fullname': 'Jack Chan', 'email': 'chenkai1989129@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/df59d16febde1a73fc98bf70f5476ba2.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'ConceptCLIP', 'role': 'read', 'createdAt': '2025-08-20T17:55:27.543Z'}}}\n"
     ]
    }
   ],
   "source": [
    "# 载入HuggingFace上的CLIP模型\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from huggingface_hub import login, whoami\n",
    "login(token=\"<YOUR_HF_TOKEN>\")  # 替换为你的HF token（生产环境中请勿硬编码）\n",
    "print(whoami())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a37b1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenk\\.conda\\envs\\pyg_monai\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\chenk\\.conda\\envs\\pyg_monai\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    }
   ],
   "source": [
    "# 载入模型和处理器，第一次会下载模型到本地缓存目录\n",
    "model = AutoModel.from_pretrained('JerrryNie/ConceptCLIP', trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained('JerrryNie/ConceptCLIP', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b4e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型载入GPU（如没有则用CPU）\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa82df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更改processor的图像预处理设置\n",
    "# BloodMNIST数据集的DataLoader已经是[0,1]范围内的浮点数，所以关闭processor中的rescale，开启normalize\n",
    "processor.image_processor.do_rescale = False\n",
    "processor.image_processor.do_normalize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207c98d",
   "metadata": {},
   "source": [
    "# 3 使用文本和图像编码器进行推理并提取、存储特征（Reason with Text and Image Encoder）\n",
    "\n",
    "## (1) 部署H5数据库用于存储输出（Deploy h5 for storing outputs）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc81632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py, hashlib, json, time\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "OUT_PATH = \"./conceptclip_features.h5\"\n",
    "D      = 1152\n",
    "T_img  = 729\n",
    "DTYPE_DYNAMIC = \"float16\"   # dynamic parts (image_*) can save space\n",
    "DTYPE_TEXT    = \"float32\"   # Text features are recommended to keep higher precision\n",
    "DTYPE_STR     = h5py.string_dtype(encoding=\"utf-8\")\n",
    "\n",
    "def _serialize_for_attr(value):\n",
    "    \"\"\"Serialize a value for storing in HDF5 attribute\"\"\"\n",
    "    return json.dumps(value, ensure_ascii=False)\n",
    "\n",
    "def _read_json_attr(f: h5py.File, key: str, default=None):\n",
    "    \"\"\"\n",
    "    从 H5 文件根属性(\"attrs\")中读取 JSON 格式的属性值并解析。\n",
    "    \"\"\"\n",
    "    if key not in f.attrs:\n",
    "        return default\n",
    "    raw = f.attrs[key]\n",
    "    if isinstance(raw, bytes):\n",
    "        raw = raw.decode(\"utf-8\")\n",
    "    if isinstance(raw, str):\n",
    "        try:\n",
    "            return json.loads(raw)\n",
    "        except json.JSONDecodeError:\n",
    "            return raw\n",
    "    return raw\n",
    "\n",
    "def _hash_texts(texts: Sequence[str]) -> str:\n",
    "    \"\"\"Compute a hash value for a list of texts\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    for t in texts:\n",
    "        h.update(t.encode(\"utf-8\")); h.update(b\"\\0\")\n",
    "    return h.hexdigest()\n",
    "\n",
    "def init_file(path, d=D, t_img=T_img, metadata: Optional[dict] = None):\n",
    "    \"\"\"Init HDF5 file structure\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        with h5py.File(path, \"w\") as f:\n",
    "            # Create main datasets\n",
    "            f.create_dataset(\"image_features\",\n",
    "                shape=(0, d), maxshape=(None, d),\n",
    "                chunks=(64, d), dtype=DTYPE_DYNAMIC, compression=\"lzf\")\n",
    "            f.create_dataset(\"image_token_features\",\n",
    "                shape=(0, t_img, d), maxshape=(None, t_img, d),\n",
    "                chunks=(4, t_img, d), dtype=DTYPE_DYNAMIC, compression=\"lzf\")\n",
    "            f.create_dataset(\"ids\",\n",
    "                shape=(0,), maxshape=(None,),\n",
    "                chunks=(4096,), dtype=\"int64\", compression=\"lzf\")\n",
    "            f.create_dataset(\"labels\",\n",
    "                shape=(0,), maxshape=(None,),\n",
    "                chunks=(4096,), dtype=\"int64\", compression=\"lzf\")\n",
    "            f.create_dataset(\"split\",\n",
    "                shape=(0,), maxshape=(None,),\n",
    "                chunks=(4096,), dtype=DTYPE_STR, compression=\"lzf\")\n",
    "            \n",
    "            # Create prompt-templates group\n",
    "            f.create_group(\"templates\")\n",
    "            \n",
    "            # Add global attributes (model parameters)\n",
    "            f.attrs[\"D\"] = d\n",
    "            f.attrs[\"T_img\"] = t_img\n",
    "            f.attrs[\"created_at\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            f.attrs[\"version\"] = \"1.0\"\n",
    "            \n",
    "    f = h5py.File(path, \"a\")\n",
    "    current_len = f[\"image_features\"].shape[0] if \"image_features\" in f else 0\n",
    "    if \"image_token_features\" not in f:\n",
    "        f.create_dataset(\"image_token_features\",\n",
    "            shape=(current_len, t_img, d), maxshape=(None, t_img, d),\n",
    "            chunks=(4, t_img, d), dtype=DTYPE_DYNAMIC, compression=\"lzf\")\n",
    "    if \"ids\" not in f:\n",
    "        f.create_dataset(\"ids\",\n",
    "            shape=(current_len,), maxshape=(None,),\n",
    "            chunks=(4096,), dtype=\"int64\", compression=\"lzf\")\n",
    "    if \"labels\" not in f:\n",
    "        ds_labels = f.create_dataset(\"labels\",\n",
    "            shape=(current_len,), maxshape=(None,),\n",
    "            chunks=(4096,), dtype=\"int64\", compression=\"lzf\")\n",
    "        if current_len > 0:\n",
    "            ds_labels[:] = np.full((current_len,), -1, dtype=\"int64\")\n",
    "    if \"split\" not in f:\n",
    "        ds_split = f.create_dataset(\"split\",\n",
    "            shape=(current_len,), maxshape=(None,),\n",
    "            chunks=(4096,), dtype=DTYPE_STR, compression=\"lzf\")\n",
    "        if current_len > 0:\n",
    "            ds_split[:] = np.array([\"unspecified\"] * current_len, dtype=object)\n",
    "    if \"templates\" not in f:\n",
    "        f.create_group(\"templates\")\n",
    "    if metadata:\n",
    "        for key, value in metadata.items():\n",
    "            try:\n",
    "                f.attrs[key] = _serialize_for_attr(value)\n",
    "            except TypeError:\n",
    "                f.attrs[key] = _serialize_for_attr(str(value))\n",
    "    return f\n",
    "\n",
    "def _to_np(x, dtype):\n",
    "    \"\"\"Convert tensor to numpy array, with specified dtype\"\"\"\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    return x.astype(dtype, copy=False)\n",
    "\n",
    "def append_batch(f: h5py.File,\n",
    "                 image_feats: torch.Tensor,            # [B, D]\n",
    "                 image_token_feats: torch.Tensor,      # [B, T_img, D]\n",
    "                 ids: np.ndarray,                     # [B] int64\n",
    "                 split_names: Optional[Sequence[str]] = None,\n",
    "                 labels: Optional[np.ndarray] = None):\n",
    "    \"\"\"Append a batch of data to the HDF5 file\"\"\"\n",
    "    ds_img = f[\"image_features\"]\n",
    "    ds_tok = f[\"image_token_features\"]\n",
    "    ds_ids = f[\"ids\"]\n",
    "    ds_labels = f[\"labels\"]\n",
    "    ds_split = f[\"split\"]\n",
    "    B = image_feats.shape[0]\n",
    "\n",
    "    n0 = ds_img.shape[0]\n",
    "    ds_img.resize(n0 + B, axis=0)\n",
    "    ds_tok.resize(n0 + B, axis=0)\n",
    "    ds_ids.resize(n0 + B, axis=0)\n",
    "    ds_labels.resize(n0 + B, axis=0)\n",
    "    ds_split.resize(n0 + B, axis=0)\n",
    "\n",
    "    ds_img[n0:n0+B, :]      = _to_np(image_feats, DTYPE_DYNAMIC)\n",
    "    ds_tok[n0:n0+B, :, :]   = _to_np(image_token_feats, DTYPE_DYNAMIC)\n",
    "    ds_ids[n0:n0+B]         = ids.astype(\"int64\", copy=False)\n",
    "\n",
    "    if labels is None:\n",
    "        labels_arr = np.full((B,), -1, dtype=\"int64\")\n",
    "    else:\n",
    "        labels_arr = np.asarray(labels, dtype=\"int64\").reshape(-1)\n",
    "        if labels_arr.shape[0] != B:\n",
    "            raise ValueError(f\"Label count {labels_arr.shape[0]} does not match batch size {B}.\")\n",
    "    ds_labels[n0:n0+B] = labels_arr\n",
    "\n",
    "    if split_names is None:\n",
    "        split_arr = np.array([\"unspecified\"] * B, dtype=object)\n",
    "    else:\n",
    "        split_arr = np.asarray(list(split_names), dtype=object).reshape(-1)\n",
    "        if split_arr.shape[0] != B:\n",
    "            raise ValueError(f\"Split count {split_arr.shape[0]} does not match batch size {B}.\")\n",
    "    ds_split[n0:n0+B] = split_arr\n",
    "\n",
    "    f.flush()\n",
    "\n",
    "def write_template(f: h5py.File,\n",
    "                   template_id: str,\n",
    "                   texts: Sequence[str],\n",
    "                   text_features: torch.Tensor,            # [K, D]\n",
    "                   text_token_features: Optional[torch.Tensor]=None # [K, T_txt, D]\n",
    "                   ):\n",
    "    \"\"\"Write text templates and features\"\"\"\n",
    "    g_root = f[\"templates\"]\n",
    "    if template_id in g_root:\n",
    "        del g_root[template_id]             # Overwrite (or change to skip after verification)\n",
    "    g = g_root.create_group(template_id)\n",
    "\n",
    "    # Main data\n",
    "    tf  = _to_np(text_features, DTYPE_TEXT)         # [K, D]\n",
    "    g.create_dataset(\"text_features\", data=tf, compression=\"lzf\")\n",
    "\n",
    "    if text_token_features is not None:\n",
    "        ttf = _to_np(text_token_features, DTYPE_TEXT)     # [K, T_txt, D]\n",
    "        g.create_dataset(\"text_token_features\", data=ttf, compression=\"lzf\")\n",
    "        T_txt = ttf.shape[1]\n",
    "    else:\n",
    "        T_txt = -1\n",
    "\n",
    "    # Save original prompts (variable-length UTF-8 strings)\n",
    "    dt_str = h5py.string_dtype(encoding='utf-8')\n",
    "    ds_txt = g.create_dataset(\"texts\", shape=(len(texts),), dtype=dt_str, compression=\"lzf\")\n",
    "    ds_txt[:] = np.array(list(texts), dtype=object)\n",
    "\n",
    "    # Metadata\n",
    "    g.attrs[\"K\"]          = tf.shape[0]\n",
    "    g.attrs[\"D\"]          = tf.shape[1]\n",
    "    g.attrs[\"T_txt\"]      = int(T_txt)\n",
    "    g.attrs[\"texts_hash\"] = _hash_texts(texts)\n",
    "    g.attrs[\"created_at\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    f.flush()\n",
    "\n",
    "def save_model_params(f: h5py.File, \n",
    "                      logit_scale: float = None,\n",
    "                      logit_bias: float = None,\n",
    "                      concept_logit_scale: float = None,\n",
    "                      concept_logit_bias: float = None):\n",
    "    \"\"\"Save key model parameters to the root attributes of the HDF5 file\"\"\"\n",
    "    if logit_scale is not None:\n",
    "        f.attrs[\"logit_scale\"] = float(logit_scale)\n",
    "    if logit_bias is not None:\n",
    "        f.attrs[\"logit_bias\"] = float(logit_bias)\n",
    "    if concept_logit_scale is not None:\n",
    "        f.attrs[\"concept_logit_scale\"] = float(concept_logit_scale)\n",
    "    if concept_logit_bias is not None:\n",
    "        f.attrs[\"concept_logit_bias\"] = float(concept_logit_bias)\n",
    "    f.flush()\n",
    "\n",
    "def load_model_params(f: h5py.File) -> dict:\n",
    "    \"\"\"Load model parameters from HDF5 file\"\"\"\n",
    "    params = {}\n",
    "    for key in [\"logit_scale\", \"logit_bias\", \"concept_logit_scale\", \"concept_logit_bias\"]:\n",
    "        if key in f.attrs:\n",
    "            params[key] = f.attrs[key]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5baaee",
   "metadata": {},
   "source": [
    "## (2) 使用文本编码器计算并保存概念文本特征到H5（Compute and save concept text features to H5, using the Text Encoder）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aea84e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored templates:\n",
      "  - concept_prompts_t01: 15 prompts\n",
      "  - concept_prompts_t02: 15 prompts\n",
      "  - concept_prompts_t03: 15 prompts\n",
      "  - concept_prompts_t04: 15 prompts\n",
      "  - concept_prompts_t05: 15 prompts\n",
      "  - concept_prompts_t06: 15 prompts\n",
      "  - concept_prompts_t07: 15 prompts\n",
      "  - concept_prompts_t08: 15 prompts\n",
      "  - concept_prompts_t09: 15 prompts\n",
      "  - label_prompts_t01: 8 prompts\n",
      "  - label_prompts_t02: 8 prompts\n",
      "  - label_prompts_t03: 8 prompts\n"
     ]
    }
   ],
   "source": [
    "def _maybe_to_scalar(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.detach()\n",
    "        if x.numel() == 1:\n",
    "            return float(x.item())\n",
    "        try:\n",
    "            return float(x.squeeze().item())\n",
    "        except Exception:\n",
    "            return None\n",
    "    if hasattr(x, \"item\"):\n",
    "        try:\n",
    "            return float(x.item())\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "stored_templates = []\n",
    "with init_file(OUT_PATH, metadata=DB_METADATA) as f:\n",
    "    concept_texts_in_file = _read_json_attr(f, \"concept_texts\", concept_list)\n",
    "    concept_template_list = _read_json_attr(f, \"prompt_temp_for_concepts\", concept_prompt_template_list)\n",
    "    label_texts_in_file = _read_json_attr(f, \"label_texts\", label_list)\n",
    "    label_template_list = _read_json_attr(f, \"prompt_temp_for_labels\", label_prompt_template_list)\n",
    "\n",
    "    template_texts_map = {}\n",
    "    if isinstance(concept_template_list, (list, tuple)) and concept_texts_in_file:\n",
    "        for idx, template in enumerate(concept_template_list, start=1):\n",
    "            formatted_texts = [template.format(text) for text in concept_texts_in_file]\n",
    "            template_key = f\"concept_prompts_t{idx:02d}\"\n",
    "            template_texts_map[template_key] = formatted_texts\n",
    "    if isinstance(label_template_list, (list, tuple)) and label_texts_in_file:\n",
    "        for idx, template in enumerate(label_template_list, start=1):\n",
    "            formatted_label_texts = [template.format(text) for text in label_texts_in_file]\n",
    "            template_key = f\"label_prompts_t{idx:02d}\"\n",
    "            template_texts_map[template_key] = formatted_label_texts\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for template_id, template_texts in template_texts_map.items():\n",
    "            text_inputs = processor(text=template_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            text_cls, text_tokens = model.encode_text(text_inputs[\"input_ids\"], normalize=True)  # [K, D], [K, T_txt, D]\n",
    "            text_tokens_proj = model.text_proj(text_tokens) if hasattr(model, \"text_proj\") else text_tokens\n",
    "            write_template(f, template_id=template_id, texts=template_texts, text_features=text_cls, text_token_features=text_tokens_proj)\n",
    "            stored_templates.append((template_id, text_cls.shape[0]))\n",
    "    params_kwargs = {\n",
    "        \"logit_scale\": _maybe_to_scalar(getattr(model, \"logit_scale\", None)),\n",
    "        \"logit_bias\": _maybe_to_scalar(getattr(model, \"logit_bias\", None)),\n",
    "        \"concept_logit_scale\": _maybe_to_scalar(getattr(model, \"concept_logit_scale\", None)),\n",
    "        \"concept_logit_bias\": _maybe_to_scalar(getattr(model, \"concept_logit_bias\", None)),\n",
    "    }\n",
    "    save_model_params(f, **{k: v for k, v in params_kwargs.items() if v is not None})\n",
    "\n",
    "print(\"Stored templates:\")\n",
    "for template_id, count in stored_templates:\n",
    "    print(f\"  - {template_id}: {count} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b7608",
   "metadata": {},
   "source": [
    "## (3) 使用图像编码器计算并保存图像（token）特征到H5（Compute and save image (token) features to H5, using the Image Encoder）\n",
    "token即各27×27的patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd931cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip train: already stored 11959/11959 samples.\n",
      "Skip val: already stored 1712/1712 samples.\n",
      "Skip test: already stored 3421/3421 samples.\n",
      "No new samples were appended.\n"
     ]
    }
   ],
   "source": [
    "# Using Image Encoder, compute and save image (token) features to H5\n",
    "\n",
    "# Define data splits and their loaders\n",
    "split_loaders = [\n",
    "    (\"train\", train_loader),\n",
    "    (\"val\", valid_loader),\n",
    "    (\"test\", test_loader),\n",
    "]\n",
    "\n",
    "def encode_and_store_image_features(split_loaders):\n",
    "    \"\"\"Traverse each data split and write image features to HDF5\"\"\"\n",
    "    written_counts = {}\n",
    "    with torch.no_grad():\n",
    "        with init_file(OUT_PATH, metadata=DB_METADATA) as f:\n",
    "            existing_counts = {}\n",
    "            if \"split_counts\" in f.attrs:\n",
    "                try:\n",
    "                    existing_counts = json.loads(f.attrs[\"split_counts\"])\n",
    "                except Exception:\n",
    "                    existing_counts = {}\n",
    "            start_idx = f[\"image_features\"].shape[0]\n",
    "            for split_name, loader in split_loaders:\n",
    "                expected = len(loader.dataset)\n",
    "                recorded = int(existing_counts.get(split_name, 0) or 0)\n",
    "                if recorded >= expected:\n",
    "                    print(f\"Skip {split_name}: already stored {recorded}/{expected} samples.\")\n",
    "                    continue\n",
    "\n",
    "                processed_in_split = 0\n",
    "                for imgs, labels in tqdm(loader, desc=f\"{split_name} split\"):\n",
    "                    batch_total = imgs.shape[0]\n",
    "                    if processed_in_split + batch_total <= recorded:\n",
    "                        processed_in_split += batch_total\n",
    "                        continue\n",
    "                    if processed_in_split < recorded:\n",
    "                        offset = recorded - processed_in_split\n",
    "                        imgs = imgs[offset:]\n",
    "                        labels = labels[offset:]\n",
    "                        processed_in_split = recorded\n",
    "                        batch_total = imgs.shape[0]\n",
    "\n",
    "                    pixel_inputs = processor(images=imgs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                    pixel_inputs = pixel_inputs[\"pixel_values\"].to(device)\n",
    "                    img_cls, img_tokens = model.encode_image(pixel_inputs, normalize=True)   # [B,1152], [B,729,1152]\n",
    "                    img_tokens_proj = model.image_proj(img_tokens) if hasattr(model, \"image_proj\") else img_tokens  #  [B,729,1152]\n",
    "                    batch_size = img_cls.shape[0]\n",
    "                    batch_ids = np.arange(start_idx, start_idx + batch_size, dtype=np.int64)\n",
    "                    labels_tensor = labels.view(-1) if hasattr(labels, \"view\") else labels\n",
    "                    labels_np = np.asarray(labels_tensor, dtype=np.int64).reshape(-1)\n",
    "                    append_batch(\n",
    "                        f,\n",
    "                        image_feats=img_cls,\n",
    "                        image_token_feats=img_tokens_proj,\n",
    "                        ids=batch_ids,\n",
    "                        split_names=[split_name] * batch_size,\n",
    "                        labels=labels_np,\n",
    "                    )\n",
    "                    start_idx += batch_size\n",
    "                    processed_in_split += batch_size\n",
    "                    written_counts[split_name] = written_counts.get(split_name, 0) + batch_size\n",
    "\n",
    "            # Update split counts in file attributes\n",
    "            for split_name, count in written_counts.items():\n",
    "                existing_counts[split_name] = int(existing_counts.get(split_name, 0) or 0) + count\n",
    "            f.attrs[\"split_counts\"] = json.dumps(existing_counts)\n",
    "            f.flush()\n",
    "\n",
    "    total_new = sum(written_counts.values())\n",
    "    if total_new == 0:\n",
    "        print(\"No new samples were appended.\")\n",
    "    else:\n",
    "        print(f\"Appended {total_new} samples to {OUT_PATH}.\")\n",
    "        for split_name, count in written_counts.items():\n",
    "            print(f\"  - {split_name}: {count}\")\n",
    "\n",
    "encode_and_store_image_features(split_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6e05b",
   "metadata": {},
   "source": [
    "## (4) 验证数据库内容（Validate H5 contents）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed83f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples stored: 17092\n",
      "image_features dataset shape: (17092, 1152)\n",
      "image_token_features dataset shape: (17092, 729, 1152)\n",
      "Preview ids: [0 1 2 3 4]\n",
      "Preview labels: [7 3 6 6 7]\n",
      "Preview splits: [b'train' b'train' b'train' b'train' b'train']\n",
      "Recorded split counts: {'train': 11959, 'val': 1712, 'test': 3421}\n",
      "label_texts: ['basophil', 'eosinophil', 'erythroblast', '...']\n",
      "prompt_temp_for_labels: ['a microscopic image of a {} cell', 'a peripheral blood smear image of a {}', 'a bloodcell of {}']\n",
      "concept_texts: ['Segmented nucleus', 'Band nucleus (band form)', 'Reniform / indented nucleus', '...']\n",
      "prompt_temp_for_concepts: ['a cell photo with sign of {}', 'a photo of a cell with {}', 'a cell image indicating {}', '...']\n",
      "Templates stored: ['concept_prompts_t01', 'concept_prompts_t02', 'concept_prompts_t03', 'concept_prompts_t04', 'concept_prompts_t05', 'concept_prompts_t06', 'concept_prompts_t07', 'concept_prompts_t08', 'concept_prompts_t09', 'label_prompts_t01', 'label_prompts_t02', 'label_prompts_t03']\n",
      "  • Template 'concept_prompts_t01' -> K=15, D=1152, sample texts=[b'a cell photo with sign of Segmented nucleus'\n",
      " b'a cell photo with sign of Band nucleus (band form)'\n",
      " b'a cell photo with sign of Reniform / indented nucleus']\n",
      "  • Template 'concept_prompts_t02' -> K=15, D=1152, sample texts=[b'a photo of a cell with Segmented nucleus'\n",
      " b'a photo of a cell with Band nucleus (band form)'\n",
      " b'a photo of a cell with Reniform / indented nucleus']\n",
      "Stored model params: {'logit_scale': 4.570647716522217, 'logit_bias': -11.16147232055664, 'concept_logit_scale': 4.511484146118164, 'concept_logit_bias': -11.0343017578125}\n"
     ]
    }
   ],
   "source": [
    "def validate_h5(path: str = OUT_PATH, max_templates: int = 2):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"File '{path}' does not exist yet.\")\n",
    "        return\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        num_samples = f[\"image_features\"].shape[0]\n",
    "        print(f\"Total samples stored: {num_samples}\")\n",
    "        print(f\"image_features dataset shape: {f['image_features'].shape}\")\n",
    "        print(f\"image_token_features dataset shape: {f['image_token_features'].shape}\")\n",
    "        ids_preview = f[\"ids\"][:5]\n",
    "        labels_preview = f[\"labels\"][:5]\n",
    "        split_preview = f[\"split\"][:5]\n",
    "        print(f\"Preview ids: {ids_preview}\")\n",
    "        print(f\"Preview labels: {labels_preview}\")\n",
    "        print(f\"Preview splits: {split_preview}\")\n",
    "        try:\n",
    "            split_counts = json.loads(f.attrs.get(\"split_counts\", \"{}\"))\n",
    "        except Exception:\n",
    "            split_counts = {}\n",
    "        print(f\"Recorded split counts: {split_counts}\")\n",
    "        metadata_keys = [\n",
    "            \"label_texts\",\n",
    "            \"prompt_temp_for_labels\",\n",
    "            \"concept_texts\",\n",
    "            \"prompt_temp_for_concepts\",\n",
    "        ]\n",
    "        for key in metadata_keys:\n",
    "            value = _read_json_attr(f, key, None)\n",
    "            if value is None:\n",
    "                continue\n",
    "            if isinstance(value, list):\n",
    "                preview = value[:3] + ([\"...\"] if len(value) > 3 else [])\n",
    "                print(f\"{key}: {preview}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        templates = list(f[\"templates\"].keys())\n",
    "        print(f\"Templates stored: {templates}\")\n",
    "        for template_id in templates[:max_templates]:\n",
    "            g = f[\"templates\"][template_id]\n",
    "            texts_sample = g[\"texts\"][:3] if \"texts\" in g else []\n",
    "            print(f\"  • Template '{template_id}' -> K={g.attrs.get('K')}, D={g.attrs.get('D')}, sample texts={texts_sample}\")\n",
    "        params = load_model_params(f)\n",
    "        print(f\"Stored model params: {params}\")\n",
    "\n",
    "validate_h5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
